{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14534727,"sourceType":"datasetVersion","datasetId":9283142}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install mss opencv-python pynput \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:17:23.501743Z","iopub.status.idle":"2026-01-18T07:17:23.502114Z","shell.execute_reply.started":"2026-01-18T07:17:23.501945Z","shell.execute_reply":"2026-01-18T07:17:23.501964Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"https://www.msn.com/en-in/play/games/speed-master/cg-9nj7v0n9dwzs?cgfrom=cg_ntp_sd_cardgameitem_recentlyplayed&ocid=msedgntp&cvid=696c7d8959b44cb9b5db9b1d6846deb8&ei=2","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport mss\n\nroi = None\ndrawing = False\nix, iy = -1, -1\n\ndef mouse_callback(event, x, y, flags, param):\n    global ix, iy, drawing, roi\n\n    if event == cv2.EVENT_LBUTTONDOWN:\n        drawing = True\n        ix, iy = x, y\n\n    elif event == cv2.EVENT_MOUSEMOVE and drawing:\n        img_copy = img.copy()\n        cv2.rectangle(img_copy, (ix, iy), (x, y), (0, 255, 0), 2)\n        cv2.imshow(\"Select ROI\", img_copy)\n\n    elif event == cv2.EVENT_LBUTTONUP:\n        drawing = False\n        roi = (ix, iy, x, y)\n        cv2.rectangle(img, (ix, iy), (x, y), (0, 255, 0), 2)\n        cv2.imshow(\"Select ROI\", img)\n\n# Capture full screen once\nwith mss.mss() as sct:\n    monitor = sct.monitors[1]  # full screen\n    img = np.array(sct.grab(monitor))\n    img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n\ncv2.namedWindow(\"Select ROI\")\ncv2.setMouseCallback(\"Select ROI\", mouse_callback)\n\nprint(\"ðŸ–±ï¸ Drag mouse to select game area, then press ENTER\")\n\nwhile True:\n    cv2.imshow(\"Select ROI\", img)\n    key = cv2.waitKey(1) & 0xFF\n    if key == 13 and roi is not None:  # ENTER key\n        break\n\ncv2.destroyAllWindows()\n\nx1, y1, x2, y2 = roi\n\nMONITOR = {\n    \"top\": min(y1, y2),\n    \"left\": min(x1, x2),\n    \"width\": abs(x2 - x1),\n    \"height\": abs(y2 - y1)\n}\n\nprint(\"\\nâœ… COPY THIS INTO YOUR CODE:\\n\")\nprint(\"MONITOR =\", MONITOR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T15:16:38.066358Z","iopub.execute_input":"2026-01-17T15:16:38.067018Z","iopub.status.idle":"2026-01-17T15:16:38.083284Z","shell.execute_reply.started":"2026-01-17T15:16:38.066990Z","shell.execute_reply":"2026-01-17T15:16:38.082410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport mss\nimport numpy as np\nimport pandas as pd\nimport time\nfrom pynput import keyboard\n\n# ================= CONFIG =================\nSAVE_DIR = \"dataset\"\nFRAME_DIR = os.path.join(SAVE_DIR, \"frames\")\nos.makedirs(FRAME_DIR, exist_ok=True)\n\nCSV_PATH = os.path.join(SAVE_DIR, \"actions.csv\")\nFPS = 15\nIMG_SIZE = (84, 84)\n\n# Define screen region manually (adjust!)\nMONITOR = {\"top\": 200, \"left\": 300, \"width\": 640, \"height\": 480}\n\nACTIONS = [\"LEFT\", \"RIGHT\", \"UP\", \"DOWN\", \"SPACE\", \"NO_ACTION\"]\npressed_keys = set()\ndata = []\n\n# ================= KEYBOARD LISTENER =================\ndef on_press(key):\n    try:\n        pressed_keys.add(key.char)\n    except:\n        pressed_keys.add(key)\n\ndef on_release(key):\n    try:\n        pressed_keys.discard(key.char)\n    except:\n        pressed_keys.discard(key)\n\nlistener = keyboard.Listener(on_press=on_press, on_release=on_release)\nlistener.start()\n\n# ================= ACTION MAPPING =================\ndef get_action():\n    if keyboard.Key.left in pressed_keys:\n        return \"LEFT\"\n    if keyboard.Key.right in pressed_keys:\n        return \"RIGHT\"\n    if keyboard.Key.up in pressed_keys:\n        return \"UP\"\n    if keyboard.Key.down in pressed_keys:\n        return \"DOWN\"\n    if keyboard.Key.space in pressed_keys:\n        return \"SPACE\"\n    return \"NO_ACTION\"\n\n# ================= RECORD LOOP =================\nsct = mss.mss()\nframe_id = 0\n\nprint(\"ðŸŽ® START PLAYING â€” Press Ctrl+C to stop\")\n\ntry:\n    while True:\n        start = time.time()\n\n        img = np.array(sct.grab(MONITOR))\n        frame = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)\n        frame = cv2.resize(frame, IMG_SIZE)\n\n        action = get_action()\n\n        frame_name = f\"{frame_id:06d}\"\n        np.save(os.path.join(FRAME_DIR, frame_name), frame)\n\n        data.append([frame_name, action])\n\n        frame_id += 1\n\n        time.sleep(max(0, (1 / FPS) - (time.time() - start)))\n\nexcept KeyboardInterrupt:\n    print(\"\\nðŸ›‘ Recording stopped\")\n\nfinally:\n    df = pd.DataFrame(data, columns=[\"frame_id\", \"action\"])\n    df.to_csv(CSV_PATH, index=False)\n    print(f\"âœ… Dataset saved with {len(df)} samples\")\n# ================= Gameplay Record =================","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport mss\nimport numpy as np\nimport pandas as pd\nimport time\nfrom pynput import keyboard, mouse\n\n# ================= CONFIG =================\nSAVE_DIR = \"dataset\"\nFRAME_DIR = os.path.join(SAVE_DIR, \"frames\")\nos.makedirs(FRAME_DIR, exist_ok=True)\n\nCSV_PATH = os.path.join(SAVE_DIR, \"actions_raw.csv\")\n\nFPS = 15\nIMG_SIZE = (84, 84)\n\nMONITOR = {'top': 263, 'left': 337, 'width': 734, 'height': 869}\n\n# ================= GLOBAL STATE =================\npressed_keys = set()\nmouse_pos = None\nmouse_clicked = False\n\ndata = []\nframe_id = 0\n\n# ================= KEYBOARD LISTENER =================\ndef on_key_press(key):\n    try:\n        pressed_keys.add(key.char)\n    except:\n        pressed_keys.add(key)\n\ndef on_key_release(key):\n    try:\n        pressed_keys.discard(key.char)\n    except:\n        pressed_keys.discard(key)\n\nkeyboard.Listener(on_press=on_key_press, on_release=on_key_release).start()\n\n# ================= MOUSE LISTENER =================\ndef on_mouse_click(x, y, button, pressed):\n    global mouse_clicked, mouse_pos\n    if pressed:\n        mouse_clicked = True\n        mouse_pos = (x, y)\n\nmouse.Listener(on_click=on_mouse_click).start()\n\n# ================= ACTION MAPPING =================\ndef get_action():\n    if mouse_clicked:\n        return \"MOUSE_CLICK\"\n    if keyboard.Key.left in pressed_keys:\n        return \"LEFT\"\n    if keyboard.Key.right in pressed_keys:\n        return \"RIGHT\"\n    return \"NO_ACTION\"\n\n# ================= RECORD LOOP =================\nsct = mss.mss()\n\nprint(\"ðŸŽ® START PLAYING â€” Ctrl+C to stop\")\n\ntry:\n    while True:\n        start = time.time()\n\n        img = np.array(sct.grab(MONITOR))\n        frame = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)\n        frame = cv2.resize(frame, IMG_SIZE)\n\n        action = get_action()\n\n        # Mouse coordinates relative to MONITOR\n        if mouse_clicked and mouse_pos is not None:\n            mx, my = mouse_pos\n            mx -= MONITOR[\"left\"]\n            my -= MONITOR[\"top\"]\n        else:\n            mx, my = np.nan, np.nan\n\n        frame_name = f\"{frame_id:06d}\"\n        np.save(os.path.join(FRAME_DIR, frame_name), frame)\n\n        data.append([frame_name, action, mx, my])\n\n        # Reset mouse state\n        mouse_clicked = False\n        mouse_pos = None\n\n        frame_id += 1\n        time.sleep(max(0, (1 / FPS) - (time.time() - start)))\n\nexcept KeyboardInterrupt:\n    print(\"\\nðŸ›‘ Recording stopped\")\n\nfinally:\n    df = pd.DataFrame(\n        data,\n        columns=[\"frame_id\", \"action\", \"mouse_x\", \"mouse_y\"]\n    )\n    df.to_csv(CSV_PATH, index=False)\n    print(f\"âœ… Raw dataset saved: {CSV_PATH}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# ================= CONFIG =================\nDATASET_DIR = \"dataset\"\nFRAME_DIR = os.path.join(DATASET_DIR, \"frames\")\n\nRAW_CSV = os.path.join(DATASET_DIR, \"actions_raw.csv\")\nCLEAN_CSV = os.path.join(DATASET_DIR, \"actions_clean.csv\")\n\n# ================= LOAD =================\ndf = pd.read_csv(RAW_CSV)\n\nprint(\"Original samples:\", len(df))\nprint(df[\"action\"].value_counts())\n\n# ================= FIND CLICK ROWS =================\nclick_rows = df[df[\"action\"] == \"MOUSE_CLICK\"]\nclean_df = df[df[\"action\"] != \"MOUSE_CLICK\"].copy()\n\n# ================= DELETE CLICK FRAMES =================\ndeleted = 0\nfor fid in click_rows[\"frame_id\"]:\n    path = os.path.join(FRAME_DIR, f\"{int(fid):06d}.npy\")\n    if os.path.exists(path):\n        os.remove(path)\n        deleted += 1\n\nprint(f\"Deleted {deleted} frames with mouse clicks\")\n\n# ================= DROP MOUSE COORDINATES =================\nclean_df = clean_df.drop(columns=[\"mouse_x\", \"mouse_y\"])\n\n# ================= SAVE CLEAN CSV =================\nclean_df.to_csv(CLEAN_CSV, index=False)\n\nprint(\"Clean samples:\", len(clean_df))\nprint(f\"âœ… Clean dataset saved: {CLEAN_CSV}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''import pandas as pd\n\ndf = pd.read_csv(r\"D:\\\\venv\\\\Research\\\\CV\\\\dataset\\\\actions.csv\")\ndf[\"action\"] = df[\"action\"].replace({\"NO_ACTION\":1,\"LEFT\":6, \"RIGHT\":6})\nprint(len(df))\nprint(df[\"action\"].value_counts(normalize=True))'''\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\n#print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:23:32.617919Z","iopub.execute_input":"2026-01-18T07:23:32.618282Z","iopub.status.idle":"2026-01-18T07:23:47.808400Z","shell.execute_reply.started":"2026-01-18T07:23:32.618249Z","shell.execute_reply":"2026-01-18T07:23:47.807780Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DATASET_PATH = \"/kaggle/input/game-ds/dataset\"\nFRAME_PATH = os.path.join(DATASET_PATH, \"frames\")\nACTION_FILE = os.path.join(DATASET_PATH, \"actions.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:23:47.809712Z","iopub.execute_input":"2026-01-18T07:23:47.810408Z","iopub.status.idle":"2026-01-18T07:23:47.815202Z","shell.execute_reply.started":"2026-01-18T07:23:47.810366Z","shell.execute_reply":"2026-01-18T07:23:47.814346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================= MODEL CONFIG =================\nIMG_H = 84\nIMG_W = 84\nCHANNELS = 1\nBATCH_SIZE = 64\nEPOCHS = 150\nSEQ_LEN = 5\n\n# CNN parameters\nCNN_FILTERS = [32, 64, 64, 128, 128]\nCNN_KERNEL_SIZES = [8, 4, 3, 3, 3]\nCNN_STRIDES = [4, 2, 1, 1, 1]\nUSE_BATCHNORM = True\n\n\n# LSTM & Dense\nLSTM_UNITS = 128\nDENSE_UNITS = 128\nDROPOUT_RATE = 0.3\nLSTM_DROPOUT = 0.0\n\n# Optimizer\nLEARNING_RATE = 1e-4\n\n# Output\nOUTPUT_UNITS = 1          # binary EVADE\nOUTPUT_ACTIVATION = \"sigmoid\"\nLOSS_FUNCTION = \"binary_crossentropy\"\nMETRICS = [\"accuracy\"]\n\n# Binary EVADE setup\nEVADE_THRESHOLD = 0.45\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:23:47.816336Z","iopub.execute_input":"2026-01-18T07:23:47.816622Z","iopub.status.idle":"2026-01-18T07:23:47.862826Z","shell.execute_reply.started":"2026-01-18T07:23:47.816594Z","shell.execute_reply":"2026-01-18T07:23:47.862238Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SEQ_LEN = 3\nLSTM_UNITS = 128\nDENSE_UNITS = 128\nDROPOUT_RATE = 0.3\nLEARNING_RATE = 1e-4\nBATCH_SIZE = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:50:12.990534Z","iopub.execute_input":"2026-01-17T13:50:12.990789Z","iopub.status.idle":"2026-01-17T13:50:13.001281Z","shell.execute_reply.started":"2026-01-17T13:50:12.990757Z","shell.execute_reply":"2026-01-17T13:50:13.000695Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ACTIONS = [\"LEFT\", \"RIGHT\", \"UP\", \"DOWN\", \"SPACE\", \"NO_ACTION\"]\naction_to_id = {a: i for i, a in enumerate(ACTIONS)}\nid_to_action = {i: a for a, i in action_to_id.items()}\nNUM_ACTIONS = len(ACTIONS)","metadata":{}},{"cell_type":"code","source":"\n# Binary action: EVADE or NOT\nACTION_MAP = {\n    \"NO_ACTION\": 0,\n    \"LEFT\": 1,\n    \"RIGHT\": 1\n}\n\ndf = pd.read_csv(os.path.join(DATASET_PATH, \"actions.csv\"))\n\n# Relabel LEFT/RIGHT â†’ EVADE\ndf[\"label\"] = df[\"action\"].map(ACTION_MAP)\n\nprint(df[\"label\"].value_counts(normalize=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:23:47.864421Z","iopub.execute_input":"2026-01-18T07:23:47.864670Z","iopub.status.idle":"2026-01-18T07:23:47.917634Z","shell.execute_reply.started":"2026-01-18T07:23:47.864648Z","shell.execute_reply":"2026-01-18T07:23:47.917079Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"actions_df = pd.read_csv(ACTION_FILE)\nactions_df[\"action_id\"] = actions_df[\"action\"].map(action_to_id)\n\nprint(actions_df.head())\nprint(\"Action distribution:\", Counter(actions_df[\"action\"]))\n","metadata":{}},{"cell_type":"markdown","source":"def load_frame(frame_id):\n    path = os.path.join(FRAME_PATH, f\"{frame_id}.npy\")\n    frame = np.load(path)\n    \n    if frame.ndim == 2:\n        frame = frame[..., np.newaxis]\n        \n    frame = frame.astype(np.float32) / 255.0\n    return frame\n","metadata":{}},{"cell_type":"code","source":"FRAME_DIR = os.path.join(DATASET_PATH, \"frames\")\n\ndef load_frame(frame_id):\n    frame = np.load(\n        os.path.join(FRAME_DIR, f\"{int(frame_id):06d}.npy\")\n    )\n    frame = frame.astype(np.float32) / 255.0\n    frame = frame[..., np.newaxis]\n    return frame\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:23:47.918377Z","iopub.execute_input":"2026-01-18T07:23:47.918639Z","iopub.status.idle":"2026-01-18T07:23:47.923405Z","shell.execute_reply.started":"2026-01-18T07:23:47.918605Z","shell.execute_reply":"2026-01-18T07:23:47.922604Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"def create_sequences(df, seq_len):\n    X, y = [], []\n    \n    for i in range(len(df) - seq_len):\n        frames = []\n        for j in range(seq_len):\n            frame_id = df.iloc[i + j][\"frame_id\"]\n            frames.append(load_frame(frame_id))\n        \n        X.append(np.stack(frames))\n        y.append(df.iloc[i + seq_len][\"action_id\"])\n        \n    return np.array(X), np.array(y)\n","metadata":{}},{"cell_type":"code","source":"def create_sequences(df, seq_len):\n    X, y = [], []\n\n    for i in range(len(df) - seq_len):\n        frames = []\n        for j in range(seq_len):\n            frames.append(load_frame(df.iloc[i + j][\"frame_id\"]))\n\n        X.append(np.stack(frames))\n        y.append(df.iloc[i + seq_len][\"label\"])\n\n    return np.array(X), np.array(y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:23:47.924320Z","iopub.execute_input":"2026-01-18T07:23:47.924771Z","iopub.status.idle":"2026-01-18T07:23:47.937244Z","shell.execute_reply.started":"2026-01-18T07:23:47.924740Z","shell.execute_reply":"2026-01-18T07:23:47.936617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X, y = create_sequences(df, SEQ_LEN)\nprint(\"X shape:\", X.shape)  # (N, SEQ_LEN, 84, 84, 1)\nprint(\"y shape:\", y.shape)\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, shuffle=True, random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:23:48.541981Z","iopub.execute_input":"2026-01-18T07:23:48.542334Z","iopub.status.idle":"2026-01-18T07:25:00.069738Z","shell.execute_reply.started":"2026-01-18T07:23:48.542299Z","shell.execute_reply":"2026-01-18T07:25:00.069069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#y = tf.keras.utils.to_categorical(y, NUM_ACTIONS)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"class_counts = np.sum(y_train, axis=0)\nclass_weights = {\n    i: max(class_counts) / class_counts[i]\n    for i in range(NUM_ACTIONS)\n}\n\nprint(\"Class weights:\", class_weights)\n","metadata":{}},{"cell_type":"code","source":"neg = np.sum(y_train == 0)\npos = np.sum(y_train == 1)\n\nclass_weight = {\n    0: 1.0,\n    1: 6.0   # EVADE is rare and important\n}\n\nprint(\"Class weight:\", class_weight)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:25:00.071049Z","iopub.execute_input":"2026-01-18T07:25:00.071391Z","iopub.status.idle":"2026-01-18T07:25:00.076260Z","shell.execute_reply.started":"2026-01-18T07:25:00.071367Z","shell.execute_reply":"2026-01-18T07:25:00.075297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras import layers, models, optimizers\n\ndef build_model():\n    # -------- CNN backbone --------\n    cnn = models.Sequential(name=\"cnn_backbone\")\n\n    for i in range(len(CNN_FILTERS)):\n        cnn.add(\n            layers.Conv2D(\n                filters=CNN_FILTERS[i],\n                kernel_size=CNN_KERNEL_SIZES[i],\n                strides=CNN_STRIDES[i],\n                padding=\"same\",\n                activation=\"relu\",\n                name=f\"conv_{i+1}\"\n            )\n        )\n    \n        if USE_BATCHNORM:\n            cnn.add(layers.BatchNormalization(name=f\"bn_{i+1}\"))\n    \n    cnn.add(layers.Flatten(name=\"flatten\"))\n\n\n    # -------- Full model --------\n    model = models.Sequential(name=\"speed_master_evade_model\")\n\n    model.add(\n        layers.TimeDistributed(\n            cnn,\n            input_shape=(SEQ_LEN, IMG_H, IMG_W, CHANNELS),\n            name=\"time_distributed_cnn\"\n        )\n    )\n\n    model.add(\n        layers.LSTM(\n            units=LSTM_UNITS,          # 128 or 256\n            activation=\"tanh\",\n            recurrent_activation=\"sigmoid\",\n            dropout=LSTM_DROPOUT,\n            recurrent_dropout=0.0,\n            name=\"lstm\"\n        )\n    )\n\n    model.add(\n        layers.Dense(\n            DENSE_UNITS,\n            activation=\"relu\",\n            name=\"dense\"\n        )\n    )\n\n    model.add(layers.Dropout(DROPOUT_RATE))\n\n    model.add(\n        layers.Dense(\n            OUTPUT_UNITS,\n            activation=OUTPUT_ACTIVATION,\n            name=\"output\"\n        )\n    )\n\n    # -------- Optimizer (AdamW correctly used) --------\n    optimizer = optimizers.Adamax(\n        learning_rate=LEARNING_RATE,\n        weight_decay=1e-4   # IMPORTANT\n    )\n\n    model.compile(\n        optimizer=optimizer,\n        loss=LOSS_FUNCTION,\n        metrics=METRICS\n    )\n\n    return model\nmodel = build_model()\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:25:00.077235Z","iopub.execute_input":"2026-01-18T07:25:00.077497Z","iopub.status.idle":"2026-01-18T07:25:02.452836Z","shell.execute_reply.started":"2026-01-18T07:25:00.077470Z","shell.execute_reply":"2026-01-18T07:25:02.452253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"callbacks = [\n    tf.keras.callbacks.EarlyStopping(\n        monitor=\"val_loss\", patience=5, restore_best_weights=True\n    ),\n    tf.keras.callbacks.ModelCheckpoint(\n        \"speed_master_evade_model.keras\", save_best_only=True\n    )\n]\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    class_weight=class_weight,\n    callbacks=callbacks,\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:25:02.454376Z","iopub.execute_input":"2026-01-18T07:25:02.454608Z","iopub.status.idle":"2026-01-18T07:26:42.065775Z","shell.execute_reply.started":"2026-01-18T07:25:02.454586Z","shell.execute_reply":"2026-01-18T07:26:42.065043Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#model.save(\"/kaggle/working/\")\nprint(\"Model saved.\")#https://www.msn.com/en-in/play/games/speed-master/cg-9nj7v0n9dwzs?ocid=msedgntp&cgfrom=cg_landing_L2_racing&pc=DCTS&cvid=696b7b8c5be04351a5529f7438b89b7c&ei=48\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:26:42.066889Z","iopub.execute_input":"2026-01-18T07:26:42.067289Z","iopub.status.idle":"2026-01-18T07:26:42.071305Z","shell.execute_reply.started":"2026-01-18T07:26:42.067252Z","shell.execute_reply":"2026-01-18T07:26:42.070591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_val_pred_prob = model.predict(X_val).ravel()\nEVADE_THRESHOLD = 0.4\n\ny_val_pred = (y_val_pred_prob > EVADE_THRESHOLD).astype(int)\nfrom sklearn.metrics import (\n    classification_report,\n    confusion_matrix,\n    precision_score,\n    recall_score,\n    f1_score\n)\n\nprint(\"Precision:\", precision_score(y_val, y_val_pred))\nprint(\"Recall:\", recall_score(y_val, y_val_pred))\nprint(\"F1-score:\", f1_score(y_val, y_val_pred))\n\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(y_val, y_val_pred, target_names=[\"NO_ACTION\", \"EVADE\"]))\ncm = confusion_matrix(y_val, y_val_pred)\nprint(cm)\nimport numpy as np\n\nthresholds = np.linspace(0.1, 0.9, 9)\n\nfor t in thresholds:\n    y_pred_t = (y_val_pred_prob > t).astype(int)\n    rec = recall_score(y_val, y_pred_t)\n    prec = precision_score(y_val, y_pred_t)\n    print(f\"t={t:.2f} | Recall={rec:.3f} | Precision={prec:.3f}\")\nfor i in range(100):\n    if y_val[i] == 1:\n        print(i, y_val_pred_prob[i])\nWINDOW = 2\nhits = 0\ntotal = np.sum(y_val == 1)\n\nfor i in np.where(y_val == 1)[0]:\n    if np.any(y_val_pred[max(0,i-WINDOW):i+WINDOW+1] == 1):\n        hits += 1\n\nprint(\"Event recall:\", hits / total)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:26:42.072191Z","iopub.execute_input":"2026-01-18T07:26:42.072512Z","iopub.status.idle":"2026-01-18T07:26:45.142890Z","shell.execute_reply.started":"2026-01-18T07:26:42.072493Z","shell.execute_reply":"2026-01-18T07:26:45.142204Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"y_val unique:\", np.unique(y_val))\nprint(\"Pred prob min/max:\", y_val_pred_prob.min(), y_val_pred_prob.max())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:26:45.143918Z","iopub.execute_input":"2026-01-18T07:26:45.144182Z","iopub.status.idle":"2026-01-18T07:26:45.149424Z","shell.execute_reply.started":"2026-01-18T07:26:45.144161Z","shell.execute_reply":"2026-01-18T07:26:45.148765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n# IMPORTANT: probabilities, NOT binary predictions\ny_val_pred_prob = model.predict(X_val).ravel()\n\n# Compute ROC\nfpr, tpr, _ = roc_curve(y_val, y_val_pred_prob)\n\n# Compute AUC (robust way)\nroc_auc = roc_auc_score(y_val, y_val_pred_prob)\n\nprint(\"ROC AUC:\", roc_auc)\n\n# Plot\nplt.figure(figsize=(6, 6))\nplt.plot(fpr, tpr, lw=2, label=f\"ROC curve (AUC = {roc_auc:.3f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve â€“ EVADE Detection\")\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:26:45.150339Z","iopub.execute_input":"2026-01-18T07:26:45.150553Z","iopub.status.idle":"2026-01-18T07:26:46.714220Z","shell.execute_reply.started":"2026-01-18T07:26:45.150534Z","shell.execute_reply":"2026-01-18T07:26:46.713618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_prob_evade = model.predict(X_val).ravel()\ny_prob_no_action = 1.0 - y_prob_evade\nfrom sklearn.metrics import roc_auc_score\n\n# EVADE as positive class\nauc_evade = roc_auc_score(y_val, y_prob_evade)\n\n# NO_ACTION as positive class (flip labels)\nauc_no_action = roc_auc_score(1 - y_val, y_prob_no_action)\n\nprint(f\"AUC (EVADE): {auc_evade:.3f}\")\nprint(f\"AUC (NO_ACTION): {auc_no_action:.3f}\")\nfrom sklearn.metrics import roc_curve\n\nfpr_e, tpr_e, _ = roc_curve(y_val, y_prob_evade)\nfpr_n, tpr_n, _ = roc_curve(1 - y_val, y_prob_no_action)\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(6,6))\nplt.plot(fpr_e, tpr_e, label=f\"EVADE (AUC={auc_evade:.3f})\")\nplt.plot(fpr_n, tpr_n, label=f\"NO_ACTION (AUC={auc_no_action:.3f})\")\nplt.plot([0,1], [0,1], \"k--\", label=\"Random\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curves for EVADE and NO_ACTION\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:26:46.715119Z","iopub.execute_input":"2026-01-18T07:26:46.715399Z","iopub.status.idle":"2026-01-18T07:26:48.184359Z","shell.execute_reply.started":"2026-01-18T07:26:46.715363Z","shell.execute_reply":"2026-01-18T07:26:48.183731Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(7, 5))\n\nplt.plot(history.history[\"loss\"], label=\"Train Loss\")\nplt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Binary Cross-Entropy Loss\")\nplt.title(\"Training vs Validation Loss\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\nplt.figure(figsize=(7, 5))\n\nplt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\nplt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training vs Validation Accuracy\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:26:48.186433Z","iopub.execute_input":"2026-01-18T07:26:48.186711Z","iopub.status.idle":"2026-01-18T07:26:48.441005Z","shell.execute_reply.started":"2026-01-18T07:26:48.186689Z","shell.execute_reply":"2026-01-18T07:26:48.440283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\n\nprecision, recall, pr_thresholds = precision_recall_curve(\n    y_val, y_val_pred_prob\n)\n\nplt.figure(figsize=(6, 6))\nplt.plot(recall, precision)\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precisionâ€“Recall Curve (EVADE)\")\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:26:48.442013Z","iopub.execute_input":"2026-01-18T07:26:48.442423Z","iopub.status.idle":"2026-01-18T07:26:48.548750Z","shell.execute_reply.started":"2026-01-18T07:26:48.442391Z","shell.execute_reply":"2026-01-18T07:26:48.548170Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\nmodel = tf.keras.models.load_model(\"/kaggle/working/speed_master_evade_model.keras\")\ndef load_frame(frame_id):\n    frame = np.load(\n        os.path.join(FRAME_DIR, f\"{int(frame_id):06d}.npy\")\n    )\n    frame = frame.astype(np.float32) / 255.0\n    frame = frame[..., np.newaxis]\n    return frame\ndef get_sequence(df, start_idx):\n    frames = []\n    for i in range(SEQ_LEN):\n        frame_id = df.iloc[start_idx + i][\"frame_id\"]\n        frames.append(load_frame(frame_id))\n    return np.expand_dims(np.stack(frames), axis=0)\nseq = get_sequence(df, start_idx=100)\n\np_evade = model.predict(seq, verbose=0)[0][0]\nprint(\"EVADE probability:\", p_evade)\nEVADE_THRESHOLD = 0.4   # tune between 0.35â€“0.5\n\nif p_evade > EVADE_THRESHOLD:\n    action = \"EVADE\"\nelse:\n    action = \"NO_ACTION\"\n\nprint(action)\ndef decide_direction(frame):\n    h, w = frame.shape[:2]\n\n    left_half = frame[:, :w//2]\n    right_half = frame[:, w//2:]\n\n    # Lower mean intensity = more visual structure\n    if left_half.mean() < right_half.mean():\n        return \"LEFT\"\n    else:\n        return \"RIGHT\"\nstart_idx=100\ncurrent_frame = load_frame(df.iloc[start_idx + SEQ_LEN][\"frame_id\"]).squeeze()\n\nif p_evade > EVADE_THRESHOLD:\n    direction = decide_direction(current_frame)\nelse:\n    direction = \"NO_ACTION\"\n\nprint(direction)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:26:48.549669Z","iopub.execute_input":"2026-01-18T07:26:48.549963Z","iopub.status.idle":"2026-01-18T07:26:49.893931Z","shell.execute_reply.started":"2026-01-18T07:26:48.549932Z","shell.execute_reply":"2026-01-18T07:26:49.893266Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nEVADE_THRESHOLD = 0.45\n\nrecords = []\n\n# choose how many predictions you want to inspect\nSTART = 0\nEND = 5000   # exclusive\n\nfor start_idx in range(START, END):\n    # ----- build sequence -----\n    seq = get_sequence(df, start_idx)\n\n    # ----- predict -----\n    p_evade = model.predict(seq, verbose=0)[0][0]\n    pred_action = \"EVADE\" if p_evade > EVADE_THRESHOLD else \"NO_ACTION\"\n\n    # ----- target frame -----\n    target_row = df.iloc[start_idx + SEQ_LEN]\n    frame_id = target_row[\"frame_id\"]\n    true_action = target_row[\"action\"]\n\n    # ----- optional direction -----\n    if pred_action == \"EVADE\":\n        frame = load_frame(frame_id).squeeze()\n        direction = decide_direction(frame)\n    else:\n        direction = \"NO_ACTION\"\n\n    records.append({\n        \"frame_id\": f\"{int(frame_id):06d}\",\n        \"true_action\": true_action,\n        \"p_evade\": float(p_evade),\n        \"pred_action\": pred_action,\n        \"pred_direction\": direction\n    })\n\n# ----- build table -----\npred_table = pd.DataFrame(records)\npred_table\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:26:49.894914Z","iopub.execute_input":"2026-01-18T07:26:49.895219Z","iopub.status.idle":"2026-01-18T07:32:24.013244Z","shell.execute_reply.started":"2026-01-18T07:26:49.895194Z","shell.execute_reply":"2026-01-18T07:32:24.012544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_table[\"is_correct\"] = (\n    ((pred_table[\"true_action\"] != \"NO_ACTION\") & (pred_table[\"pred_action\"] == \"EVADE\")) |\n    ((pred_table[\"true_action\"] == \"NO_ACTION\") & (pred_table[\"pred_action\"] == \"NO_ACTION\"))\n)\n\npred_table\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:32:24.014302Z","iopub.execute_input":"2026-01-18T07:32:24.014617Z","iopub.status.idle":"2026-01-18T07:32:24.029995Z","shell.execute_reply.started":"2026-01-18T07:32:24.014588Z","shell.execute_reply":"2026-01-18T07:32:24.029398Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_table.to_csv(\"prediction_table.csv\", index=False)\nprint(\"Saved prediction_table.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:32:24.034637Z","iopub.execute_input":"2026-01-18T07:32:24.035425Z","iopub.status.idle":"2026-01-18T07:32:24.067640Z","shell.execute_reply.started":"2026-01-18T07:32:24.035391Z","shell.execute_reply":"2026-01-18T07:32:24.066936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ground truth binary label\npred_table[\"y_true\"] = pred_table[\"true_action\"].apply(\n    lambda x: 0 if x == \"NO_ACTION\" else 1\n)\n\n# Predicted binary label\npred_table[\"y_pred\"] = pred_table[\"pred_action\"].apply(\n    lambda x: 1 if x == \"EVADE\" else 0\n)\ndef classify_error(row):\n    if row.y_true == 1 and row.y_pred == 1:\n        return \"TP\"   # correct EVADE\n    if row.y_true == 0 and row.y_pred == 0:\n        return \"TN\"   # correct NO_ACTION\n    if row.y_true == 0 and row.y_pred == 1:\n        return \"FP\"   # false EVADE (overreaction)\n    if row.y_true == 1 and row.y_pred == 0:\n        return \"FN\"   # missed EVADE (dangerous)\n\npred_table[\"error_type\"] = pred_table.apply(classify_error, axis=1)\npred_table[\"error_type\"].value_counts()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:32:24.068647Z","iopub.execute_input":"2026-01-18T07:32:24.068908Z","iopub.status.idle":"2026-01-18T07:32:24.146536Z","shell.execute_reply.started":"2026-01-18T07:32:24.068886Z","shell.execute_reply":"2026-01-18T07:32:24.145835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fn_rows = pred_table[pred_table[\"error_type\"] == \"FN\"]\n\nprint(\"Number of False Negatives:\", len(fn_rows))\nfn_rows.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:32:24.147492Z","iopub.execute_input":"2026-01-18T07:32:24.147725Z","iopub.status.idle":"2026-01-18T07:32:24.158268Z","shell.execute_reply.started":"2026-01-18T07:32:24.147707Z","shell.execute_reply":"2026-01-18T07:32:24.157697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fp_rows = pred_table[pred_table[\"error_type\"] == \"FP\"]\nprint(\"Number of False Positives:\", len(fp_rows))\nfp_rows.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:32:24.159156Z","iopub.execute_input":"2026-01-18T07:32:24.159419Z","iopub.status.idle":"2026-01-18T07:32:24.177785Z","shell.execute_reply.started":"2026-01-18T07:32:24.159385Z","shell.execute_reply":"2026-01-18T07:32:24.177103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"false_cases = pred_table[pred_table[\"error_type\"].isin([\"FP\", \"FN\"])]\nfalse_cases\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:32:24.179374Z","iopub.execute_input":"2026-01-18T07:32:24.179629Z","iopub.status.idle":"2026-01-18T07:32:24.198606Z","shell.execute_reply.started":"2026-01-18T07:32:24.179610Z","shell.execute_reply":"2026-01-18T07:32:24.198077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"false_cases.to_csv(\"false_predictions.csv\", index=False)\nprint(\"Saved false_predictions.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:32:24.199348Z","iopub.execute_input":"2026-01-18T07:32:24.199604Z","iopub.status.idle":"2026-01-18T07:32:24.215154Z","shell.execute_reply.started":"2026-01-18T07:32:24.199576Z","shell.execute_reply":"2026-01-18T07:32:24.214469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\n\nframe = np.load(\"/kaggle/input/game-ds/dataset/frames/000106.npy\")\n\n# If normalized, convert back to 0â€“255\nif frame.max() <= 1.0:\n    frame = (frame * 255).astype(np.uint8)\n\n# Remove channel dimension if needed\nif frame.ndim == 3:\n    frame = frame.squeeze()\n\ncv2.imwrite(\"000113.png\", frame)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:37:42.755914Z","iopub.execute_input":"2026-01-18T07:37:42.756493Z","iopub.status.idle":"2026-01-18T07:37:42.763889Z","shell.execute_reply.started":"2026-01-18T07:37:42.756463Z","shell.execute_reply":"2026-01-18T07:37:42.762935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimg = cv2.imread(\"/kaggle/working/000113.png\", cv2.IMREAD_GRAYSCALE)\nimg = img.astype(np.uint8)\n\nedges = cv2.Canny(img, 50, 150)\n\nplt.figure(figsize=(8,4))\n\nplt.subplot(1,2,1)\nplt.title(\"Input\")\nplt.imshow(img, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(1,2,2)\nplt.title(\"Edges\")\nplt.imshow(edges, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:37:45.022992Z","iopub.execute_input":"2026-01-18T07:37:45.023802Z","iopub.status.idle":"2026-01-18T07:37:45.130727Z","shell.execute_reply.started":"2026-01-18T07:37:45.023768Z","shell.execute_reply":"2026-01-18T07:37:45.130136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\n\nNPY_DIR = \"/kaggle/input/game-ds/dataset/frames\"\nOUT_DIR = \"/kaggle/working/\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\nfor fname in os.listdir(NPY_DIR):\n    if fname.endswith(\".npy\"):\n        frame = np.load(os.path.join(NPY_DIR, fname))\n\n        if frame.max() <= 1.0:\n            frame = (frame * 255).astype(np.uint8)\n\n        if frame.ndim == 3:\n            frame = frame.squeeze()\n\n        out_name = fname.replace(\".npy\", \".png\")\n        cv2.imwrite(os.path.join(OUT_DIR, out_name), frame)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T14:47:00.836179Z","iopub.execute_input":"2026-01-17T14:47:00.836916Z","iopub.status.idle":"2026-01-17T14:47:19.321951Z","shell.execute_reply.started":"2026-01-17T14:47:00.836886Z","shell.execute_reply":"2026-01-17T14:47:19.321043Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\n\nframe = np.load(\"/kaggle/input/game-ds/dataset/frames/000044.npy\")\n\nif frame.max() <= 1.0:\n    frame = (frame * 255).astype(np.uint8)\n\nif frame.ndim == 3:\n    frame = frame.squeeze()\n\nimg = Image.fromarray(frame, mode=\"L\")\nimg.save(\"000123.png\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:35:16.513737Z","iopub.execute_input":"2026-01-18T07:35:16.514554Z","iopub.status.idle":"2026-01-18T07:35:16.523420Z","shell.execute_reply.started":"2026-01-18T07:35:16.514521Z","shell.execute_reply":"2026-01-18T07:35:16.522731Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.imshow(frame, cmap=\"gray\")\nplt.title(\"Reconstructed frame\")\nplt.axis(\"off\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T07:35:18.291741Z","iopub.execute_input":"2026-01-18T07:35:18.292506Z","iopub.status.idle":"2026-01-18T07:35:18.364231Z","shell.execute_reply.started":"2026-01-18T07:35:18.292477Z","shell.execute_reply":"2026-01-18T07:35:18.363607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimg = cv2.imread(\"D:/venv/Research/CV/00013.png\", cv2.IMREAD_GRAYSCALE)\nimg = img.astype(np.uint8)\n\nedges = cv2.Canny(img, 50, 150)\n\nplt.figure(figsize=(8,4))\n\nplt.subplot(1,2,1)\nplt.title(\"Input\")\nplt.imshow(img, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(1,2,2)\nplt.title(\"Edges\")\nplt.imshow(edges, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for _, row in fn_rows.iterrows():\n    frame = np.load(os.path.join(FRAME_DIR, f\"{int(row.frame_id):06d}.npy\"))\n    if frame.max() <= 1.0:\n        frame = (frame * 255).astype(np.uint8)\n    cv2.imwrite(f\"FN_{row.frame_id}.png\", frame)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T14:43:27.944634Z","iopub.status.idle":"2026-01-17T14:43:27.944875Z","shell.execute_reply.started":"2026-01-17T14:43:27.944746Z","shell.execute_reply":"2026-01-17T14:43:27.944758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport mss\nimport numpy as np\nimport time\nimport tensorflow as tf\nimport pyautogui\nfrom collections import deque\n\n# ================= CONFIG =================\nMODEL_PATH = \"game_imitation_model\"\nIMG_SIZE = (84, 84)\nSEQ_LEN = 5\nFPS = 12\n\n# Screen capture area (same as recording!)\nMONITOR = {\"top\": 200, \"left\": 300, \"width\": 640, \"height\": 480}\n\nACTIONS = [\"LEFT\", \"RIGHT\", \"UP\", \"DOWN\", \"SPACE\", \"NO_ACTION\"]\n\n# ========================================\n\nprint(\"ðŸ”„ Loading model...\")\nmodel = tf.keras.models.load_model(MODEL_PATH)\nprint(\"âœ… Model loaded\")\n\n# Frame buffer\nframe_buffer = deque(maxlen=SEQ_LEN)\n\n# Screen capture\nsct = mss.mss()\n\n# Key state management\ncurrent_key = None\n\ndef release_all():\n    pyautogui.keyUp(\"left\")\n    pyautogui.keyUp(\"right\")\n    pyautogui.keyUp(\"up\")\n    pyautogui.keyUp(\"down\")\n    pyautogui.keyUp(\"space\")\n\ndef press_action(action):\n    global current_key\n    release_all()\n\n    if action == \"LEFT\":\n        pyautogui.keyDown(\"left\")\n        current_key = \"left\"\n    elif action == \"RIGHT\":\n        pyautogui.keyDown(\"right\")\n        current_key = \"right\"\n    elif action == \"UP\":\n        pyautogui.keyDown(\"up\")\n        current_key = \"up\"\n    elif action == \"DOWN\":\n        pyautogui.keyDown(\"down\")\n        current_key = \"down\"\n    elif action == \"SPACE\":\n        pyautogui.keyDown(\"space\")\n        current_key = \"space\"\n    else:\n        current_key = None\n\ndef preprocess_frame():\n    img = np.array(sct.grab(MONITOR))\n    frame = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)\n    frame = cv2.resize(frame, IMG_SIZE)\n    frame = frame.astype(np.float32) / 255.0\n    frame = frame[..., np.newaxis]\n    return frame\n\nprint(\"ðŸ¤– BOT READY â€” Switch to game window in 5 seconds\")\ntime.sleep(5)\n\nprint(\"â–¶ï¸ BOT PLAYING â€” Press Ctrl+C to stop\")\n\ntry:\n    while True:\n        start = time.time()\n\n        frame = preprocess_frame()\n        frame_buffer.append(frame)\n\n        if len(frame_buffer) == SEQ_LEN:\n            input_seq = np.expand_dims(np.array(frame_buffer), axis=0)\n            preds = model.predict(input_seq, verbose=0)\n            action_id = np.argmax(preds)\n            action = ACTIONS[action_id]\n\n            press_action(action)\n            print(\"Action:\", action)\n\n        time.sleep(max(0, (1 / FPS) - (time.time() - start)))\n\nexcept KeyboardInterrupt:\n    print(\"\\nðŸ›‘ Bot stopped\")\n\nfinally:\n    release_all()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#pip install mss opencv-python pynput \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport mss\nimport csv\nimport sys\nimport time\nimport queue\nimport threading\nimport numpy as np\nimport tensorflow as tf\nimport pyautogui\nimport pyttsx3\nimport matplotlib.pyplot as plt\nfrom collections import deque\nfrom datetime import datetime\nfrom pynput import keyboard\n\n# =========================================================\n# ===================== CONFIG ============================\n# =========================================================\nlast_key_time = 0\nKEY_DEBOUNCE = 0.25\n\nMODEL_PATH = \"speed_master_evade_model.keras\"\n\nIMG_SIZE = (84, 84)\nSEQ_LEN = 5\nFPS = 15\n\nINITIAL_THRESHOLD = 0.45\nTHRESHOLD_STEP = 0.02\n\nMONITOR = {\"top\": 263, \"left\": 337, \"width\": 734, \"height\": 869}\n\nLOG_DIR = \"logs\"\nERROR_DIR = \"errors\"\n\nos.makedirs(LOG_DIR, exist_ok=True)\nos.makedirs(f\"{ERROR_DIR}/crashes\", exist_ok=True)\nos.makedirs(f\"{ERROR_DIR}/interventions\", exist_ok=True)\n\n# =========================================================\n# ===================== SAFE TTS ==========================\n# =========================================================\n\nspeech_queue = queue.Queue()\nlast_spoken = 0\n\ndef speech_worker():\n    engine = pyttsx3.init()\n    engine.setProperty(\"rate\", 180)\n    while True:\n        text = speech_queue.get()\n        if text is None:\n            break\n        engine.say(text)\n        engine.runAndWait()\n        speech_queue.task_done()\n\nspeech_thread = threading.Thread(target=speech_worker, daemon=True)\nspeech_thread.start()\n\nimport subprocess\nimport time\n\n_last_speech_time = 0\nSPEECH_DEBOUNCE = 0.3\n\ndef speak(text):\n    global _last_speech_time\n    now = time.time()\n\n    if now - _last_speech_time < SPEECH_DEBOUNCE:\n        return\n\n    _last_speech_time = now\n\n    try:\n        subprocess.Popen(\n            [\n                \"powershell\",\n                \"-Command\",\n                f'Add-Type -AssemblyName System.Speech; '\n                f'(New-Object System.Speech.Synthesis.SpeechSynthesizer).Speak(\"{text}\")'\n            ],\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL\n        )\n    except:\n        pass\n\n\ndef speak_now(text):\n    \"\"\"High-priority speech (no cooldown)\"\"\"\n    speech_queue.put(text)\n\n\n# =========================================================\n# ===================== STATE =============================\n# =========================================================\n\nEVADE_THRESHOLD = INITIAL_THRESHOLD\nadaptive_enabled = True\n\ncurrent_action = \"NO_ACTION\"\nlast_frame = None\n\nrecent_p = deque(maxlen=30)\n\n# =========================================================\n# ===================== LOGGING ===========================\n# =========================================================\n\ndef log_threshold():\n    with open(f\"{LOG_DIR}/thresholds.csv\", \"a\", newline=\"\") as f:\n        csv.writer(f).writerow([datetime.now().isoformat(), EVADE_THRESHOLD])\n\ndef log_p_evade(p):\n    with open(f\"{LOG_DIR}/p_evade.csv\", \"a\", newline=\"\") as f:\n        csv.writer(f).writerow([datetime.now().isoformat(), p, EVADE_THRESHOLD])\n\ndef log_crash(frame):\n    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    cv2.imwrite(f\"{ERROR_DIR}/crashes/crash_{ts}.png\", frame)\n    with open(f\"{LOG_DIR}/crashes.csv\", \"a\", newline=\"\") as f:\n        csv.writer(f).writerow([ts, EVADE_THRESHOLD])\n    speak(\"Crash logged\")\n\ndef log_intervention(frame, key):\n    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    cv2.imwrite(f\"{ERROR_DIR}/interventions/{key}_{ts}.png\", frame)\n    with open(f\"{LOG_DIR}/interventions.csv\", \"a\", newline=\"\") as f:\n        csv.writer(f).writerow([ts, key, EVADE_THRESHOLD])\n    speak(\"Manual intervention\")\n\n# =========================================================\n# ===================== CONTROL ===========================\n# =========================================================\n\ndef adaptive_threshold():\n    global EVADE_THRESHOLD\n    if adaptive_enabled and len(recent_p) == recent_p.maxlen:\n        mean_p = np.mean(recent_p)\n        EVADE_THRESHOLD = np.clip(mean_p + 0.08, 0.35, 0.6)\n\ndef release_all():\n    pyautogui.keyUp(\"left\")\n    pyautogui.keyUp(\"right\")\n\ndef press_action(action):\n    release_all()\n    if action == \"LEFT\":\n        pyautogui.keyDown(\"left\")\n    elif action == \"RIGHT\":\n        pyautogui.keyDown(\"right\")\n\ndef decide_direction(frame):\n    h, w = frame.shape\n    return \"LEFT\" if frame[:, :w//2].mean() < frame[:, w//2:].mean() else \"RIGHT\"\n\ndef preprocess(sct):\n    img = np.array(sct.grab(MONITOR))\n    bgr = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n    gray = cv2.resize(gray, IMG_SIZE)\n    gray = gray.astype(np.float32) / 255.0\n    return gray[..., None], bgr\n\n# =========================================================\n# ===================== KEYBOARD ==========================\n# =========================================================\n\ndef on_key_press(key):\n    global EVADE_THRESHOLD, adaptive_enabled, last_key_time\n\n    now = time.time()\n    if now - last_key_time < KEY_DEBOUNCE:\n        return\n    last_key_time = now\n\n    try:\n        if key == keyboard.Key.up:\n            adaptive_enabled = False\n            EVADE_THRESHOLD = min(0.9, EVADE_THRESHOLD + THRESHOLD_STEP)\n            speak(f\"Threshold increased to {EVADE_THRESHOLD:.2f}\")\n\n        elif key == keyboard.Key.down:\n            adaptive_enabled = False\n            EVADE_THRESHOLD = max(0.1, EVADE_THRESHOLD - THRESHOLD_STEP)\n            speak(f\"Threshold decreased to {EVADE_THRESHOLD:.2f}\")\n\n        elif key == keyboard.Key.f12:\n            if last_frame is not None:\n                log_crash(last_frame)\n\n        elif key == keyboard.Key.left or key == keyboard.Key.right:\n            if last_frame is not None:\n                log_intervention(last_frame, str(key))\n\n    except Exception as e:\n        print(e)\n        pass\n\n\nkeyboard.Listener(on_press=on_key_press).start()\n\n# =========================================================\n# ===================== ANALYSIS ==========================\n# =========================================================\n\ndef analyze_logs():\n    print(\"\\nðŸ“Š Running post-run analysis...\")\n\n    # ---- p_evade log must exist ----\n    p_evade_path = f\"{LOG_DIR}/p_evade.csv\"\n    if not os.path.exists(p_evade_path):\n        print(\"âš ï¸ No p_evade log found â€” skipping analysis\")\n        return\n\n    p_evade_log = np.atleast_2d(\n        np.genfromtxt(p_evade_path, delimiter=\",\", dtype=str)\n    )\n\n    p_vals = p_evade_log[:, 1].astype(float)\n    thr_vals = p_evade_log[:, 2].astype(float)\n\n    # ---- interventions are OPTIONAL ----\n    interventions_path = f\"{LOG_DIR}/interventions.csv\"\n\n    if os.path.exists(interventions_path):\n        interventions = np.atleast_2d(\n            np.genfromtxt(interventions_path, delimiter=\",\", dtype=str)\n        )\n        human_evade = np.zeros(len(p_vals), dtype=bool)\n        human_evade[:len(interventions)] = True\n        print(f\"âœ” Interventions found: {len(interventions)}\")\n    else:\n        human_evade = np.zeros(len(p_vals), dtype=bool)\n        print(\"âœ” No human interventions logged\")\n\n    # ---- model decisions ----\n    model_evade = p_vals > thr_vals\n\n    # ---- disagreement metrics ----\n    TP = np.sum(model_evade & human_evade)\n    FP = np.sum(model_evade & ~human_evade)\n    FN = np.sum(~model_evade & human_evade)\n\n    precision = TP / (TP + FP + 1e-6)\n    recall = TP / (TP + FN + 1e-6)\n\n    print(f\"Disagreement Precision: {precision:.3f}\")\n    print(f\"Disagreement Recall:    {recall:.3f}\")\n\n    # ---- plot p_evade vs human actions ----\n    plt.figure(figsize=(10, 4))\n    plt.plot(p_vals, label=\"p_evade\")\n    plt.axhline(np.mean(thr_vals), color=\"r\", linestyle=\"--\", label=\"threshold\")\n\n    if human_evade.any():\n        plt.scatter(\n            np.where(human_evade)[0],\n            p_vals[human_evade],\n            color=\"orange\",\n            label=\"human intervene\"\n        )\n\n    plt.legend()\n    plt.title(\"p_evade vs Human Interventions\")\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"p_evade\")\n    plt.show()\n\n\n# =========================================================\n# ===================== MAIN ==============================\n# =========================================================\n\nprint(\"ðŸ”„ Loading model...\")\nmodel = tf.keras.models.load_model(MODEL_PATH)\nprint(\"âœ… Model loaded\")\n\nsct = mss.mss()\nframes = deque(maxlen=SEQ_LEN)\n\nspeak(\"Bot starting\")\ntime.sleep(1)\nspeak(\"five\")\ntime.sleep(1)\nspeak(\"four\")\ntime.sleep(1)\nspeak(\"3\")\ntime.sleep(1)\nspeak(\"2\")\ntime.sleep(1)\nspeak(\"1\")\ntime.sleep(1)\n\nimport win32gui\nimport win32con\n\nWINDOW_NAME = \"BOT VIEW\"\n\ncv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\ncv2.resizeWindow(WINDOW_NAME, 500, 300)\n\nhwnd = win32gui.FindWindow(None, WINDOW_NAME)\nwin32gui.SetWindowPos(\n    hwnd,\n    win32con.HWND_TOPMOST,\n    0, 0, 0, 0,\n    win32con.SWP_NOMOVE | win32con.SWP_NOSIZE\n)\nspeak(\"Game Started\")\ntry:\n    while True:\n        start = time.time()\n\n        f_gray, f_bgr = preprocess(sct)\n        last_frame = f_bgr.copy()\n        frames.append(f_gray)\n\n        if len(frames) == SEQ_LEN:\n            inp = np.expand_dims(np.array(frames), axis=0)\n            p = model.predict(inp, verbose=0)[0][0]\n\n            recent_p.append(p)\n            adaptive_threshold()\n            log_p_evade(p)\n\n            if p > EVADE_THRESHOLD:\n                d = decide_direction(f_gray.squeeze())\n                if d != current_action:\n                    press_action(d)\n                    current_action = d\n            else:\n                if current_action != \"NO_ACTION\":\n                    release_all()\n                    current_action = \"NO_ACTION\"\n\n            cv2.putText(\n                f_bgr,\n                f\"p={p:.2f} thr={EVADE_THRESHOLD:.2f}\",\n                (10,30),\n                cv2.FONT_HERSHEY_SIMPLEX,\n                0.7,\n                (0,255,0),\n                2\n            )\n\n        cv2.imshow(\"BOT VIEW\", f_bgr)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n\n        #time.sleep(max(0, (1/FPS)-(time.time()-start)))\n\nexcept KeyboardInterrupt:\n    pass\n\nfinally:\n    try:\n        keyboard.Listener.stop()\n    except:\n        pass\n\n    print(\"\\nðŸ§  Saving logs and analyzing...\")\n    log_threshold()\n    release_all()\n    cv2.destroyAllWindows()\n\n    speech_queue.put(None)\n    speech_thread.join(timeout=1)\n\n    analyze_logs()\n    print(\"ðŸ›‘ Bot stopped & analysis complete\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}